# Project Meeting Notes: May 17, 2025

This document contains notes from the design session held on May 17, 2025, discussing the Clariad AI Agent Ecosystem architecture and approach.

## LangGraph Orchestration & System Architecture

LangGraph is used to implement the orchestrated workflow of agents. Each stage-specific agent is modeled as a node in a directed graph, and edges define the flow of control and data between them. The orchestrator (managed by LangGraph) coordinates agent execution according to this graph. This design follows the principle that multi-agent workflows map naturally to a graph or state machine.

Workflow of the multi-agent ecosystem through development stages. Each agent (node) produces artifacts that flow to the next. The dashed arrow indicates feedback from the last stage back to earlier stages to address issues or architecture drift.

Key aspects of the architecture:
- **Agent Nodes**: Each agent is an independent node with its own prompt and logic. They operate sequentially (with some potential branching for multiple tasks) as depicted above. The LangGraph orchestrator triggers them in order: Vision → Architecture → Task Refinement → Development → Review → Deployment → Feedback. The connections (edges) are configured so that the output of one agent becomes input context for the next. LangGraph manages these transitions and can conditionally loop or branch if needed (for example, iterating over multiple tasks).
- **Shared State & Memory**: Agents communicate by writing their results to the graph's state (a shared memory context) which subsequent agents can read. In practice, this is backed by a semantic vector store (Postgres + pgvector) to allow flexible queries. After an agent finishes (e.g. Architecture Agent produces an architecture doc), the orchestrator stores that document's content and embedding in the vector database under a tag (e.g. "ArchitectureDoc"). The next agent (Task Refinement) can then query the vector store for relevant context (e.g. embedding search for "project goals" or "architectural constraints") to inform its prompt. This shared memory ensures no agent works in isolation; all important knowledge (requirements, decisions, code summaries, past discussions, etc.) is globally available. It acts as an evolving knowledge base of the project.
- **Control Flow**: The orchestrator uses LangGraph's ability to define conditional transitions and loops. For example, the Development Agent might be invoked once per task user story (looping through a list generated by the Task agent). The Review Agent might have a conditional loop where if it finds issues with the code, it could either auto-fix them (by invoking the Development Agent again for fixes) or mark the task as needing changes. Similarly, the Feedback Agent, after generating a retrospective, might have an edge looping back to the Architecture Agent (dashed arrow in the diagram) if significant architecture drift is detected that warrants re-design. In LangGraph terms, these can be implemented as state machine transitions or router nodes that decide the next step based on agent outputs (e.g. a router node checks if Review found "tests failed" and if so, route back to Development for bug-fixing).
- **Modularity**: Each agent node is encapsulated with a clear interface (inputs and outputs), allowing the workflow to be extended or modified easily. For instance, one could insert a "Security Analysis Agent" after Development and before Review without affecting other parts. This modular design aligns with best practices for multi-agent systems, making it easier to maintain and improve each component independently. Each agent is registered as a separate tool with Claude Desktop, allowing for flexible invocation patterns.
- **Observability**: All agent actions are instrumented with Langfuse for observability. LangGraph's integration with LangChain callbacks allows capturing each step in a trace. We attach a Langfuse callback handler to the orchestrator – as each agent runs, events (prompts, responses, tool calls) are sent to Langfuse. This provides a rich trace of the workflow, enabling developers to debug issues (e.g., see why the Architecture Agent produced a certain design) and to analyze agent performance over time (e.g., how often the Review Agent finds problems). We also log key metrics: time per agent, number of iterations in dev loop, any errors/exceptions, etc., all viewable in the Langfuse dashboard. This observability is crucial for a long-running, autonomous agent pipeline in production.

## Interaction & Operation via MCP

The ecosystem is exposed through an MCP server that registers with Claude Desktop as a set of specialized tools. This MCP interface acts as the integration gateway between Claude Desktop and the agent system. From the user's perspective, they interact with Claude Desktop as usual, but Claude can invoke specialized Clariad tools when needed to perform software development tasks.

- **Conversational Collaboration**: In interactive mode, the user can converse naturally with Claude. When software development assistance is needed, Claude invokes the appropriate Clariad tool and the orchestrator delegates to the appropriate agent. For example, if the user says "List the current user stories", Claude will invoke the Task Refinement Agent's tool to summarize the backlog.
- **Autonomous Workflow**: The system also supports full autonomous execution. The user can say "Run Clariad in autonomous mode with this project specification" and Claude will invoke the autonomous workflow tool. The orchestrator will then automatically step through all agents in sequence, from Vision & Scope through Deployment and Feedback, with Claude incorporating the results at each step. Checkpoints can be built in (e.g., waiting for user approval after architecture is drafted) in this semi-autonomous mode.
- **MCP Integration**: The MCP server receives tool invocation requests from Claude Desktop and returns tool results that Claude can incorporate into its responses. It adheres to MCP message formats to ensure proper bidirectional communication. From Claude Desktop's perspective, Clariad is just a set of specialized tools it can use when needed, abstracting the complex agent ecosystem behind a familiar interface.

## Conclusion

By leveraging well-defined prompts and strong engineering practices (BDD, TDD, ADR, agile workflows), the system aligns AI activities with proven software development standards, increasing the likelihood of meaningful and correct outcomes at each stage. The approach of implementing Clariad as an MCP extension for Claude Desktop ensures that users can access these specialized capabilities through a familiar interface without requiring separate LLM connections or API keys.

This modular agent architecture can accelerate development while maintaining quality, and it can be extended or customized to different project needs, programming languages, or organizational processes with minimal friction. By combining LangChain/LangGraph's orchestration with GitHub's collaboration platform and Claude Desktop's LLM capabilities, we create an AI agent ecosystem that works much like a real-world dev team, in a repeatable and manageable way.

---

*Document Status: Draft*
*Last Updated: May 18, 2025*
*Created By: Design Team*
*Version: 0.1*
